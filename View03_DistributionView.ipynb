{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baac801b-103c-4f8d-999d-54d59241fe55",
   "metadata": {},
   "source": [
    "# Distribution View\n",
    "\n",
    "The distribution view allows to explore large-scale live-cell imaging data and focus on single-cell property distributions to find and investigate rare events or temporal developments. Therefore, we provide cell size, length, and age distributions to filter interesting candidates that are visualized as overlays on the microscope image. Moreover, the temporal development of the selected and not selected cells by the filter are visualized in terms of total cell area and count.\n",
    "\n",
    "Have fun ðŸš€ executing the notebook yourself, experience the freedom of customization in jupyter notebooks, and have a look at the video below ðŸ‘‡ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "368dd99a-1915-4c33-b8b2-dc608d1062f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"300\"\n",
       "            src=\"https://www.youtube.com/embed/qScXv45kyOU\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.YouTubeVideo at 0x7f9fb3558460>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('qScXv45kyOU', width=800, height=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692529ed-410a-4e58-a42a-adb489f6c158",
   "metadata": {},
   "source": [
    "## 1. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc182cb4-8423-43de-b20b-7afc4754ce30",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imagecodecs==2023.9.18 igraph==0.11.3 dash[diskcache]==2.14.1 dash-bootstrap-components==1.5.0 multiprocess==0.70.15 \"git+https://jugit.fz-juelich.de/publications/acia-pre.git@c989af4c3007882239dd724a2f3a8b13715d0c88#acia\" moviepy==1.0.3 ipywidgets==8.1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cd4977c-d650-4016-89d4-2c0cf8a1a7f3",
   "metadata": {},
   "source": [
    "## 2. Load segmentation & tracking information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e764beae-97eb-4ff5-9f44-d89e79a0400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "!wget -O data.zip https://fz-juelich.sciebo.de/s/3Ng8f6LG8Ed02zi/download\n",
    "\n",
    "!mkdir data\n",
    "!unzip -o data.zip -d data\n",
    "!mkdir assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b878656a-4d99-4156-85c7-f0e13d8a8e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Meta-information\n",
    "\n",
    "pixel_size = 0.072 # micrometer/pixel\n",
    "frame_step = 1/60 # 1 frame/minute\n",
    "\n",
    "image_path = \"data/03/image_stack.tiff\"\n",
    "seg_and_track_file = \"data/03/simpleTracking.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015cd9e5-827c-4f9b-987f-03bd20fe3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acia.tracking.formats import parse_simple_tracking\n",
    "\n",
    "# load segmentation and tracking information from file\n",
    "with open(seg_and_track_file, \"r\") as tf:\n",
    "    ov, tracking_graph = parse_simple_tracking(tf.read())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab6c00f-b59f-46c0-8152-b04ae4fa544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "from shapely.geometry import Polygon\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def pairwise_distances(points: np.ndarray):\n",
    "    distances = []\n",
    "\n",
    "    if len(points) == 0:\n",
    "        return distances\n",
    "\n",
    "    for a, b in zip(points, points[1:]):\n",
    "        distances.append(np.linalg.norm(a - b))\n",
    "\n",
    "    return distances\n",
    "\n",
    "# load single-cell information into pandas data frame\n",
    "cell_df = pd.DataFrame([\n",
    "    {\n",
    "        \"id\": cont.id,\n",
    "        \"frame\": cont.frame,\n",
    "        \"area\": cont.area * (pixel_size **2),\n",
    "        \"length\": np.max(pairwise_distances(np.array(cont.polygon.minimum_rotated_rectangle.exterior.coords))) * pixel_size,\n",
    "        \"contour_coordinates\": cont.coordinates,\n",
    "        \"time\": cont.frame * frame_step\n",
    "    } for cont in tqdm(ov)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59acb4-bf36-495f-8545-07dbfe2ee9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c70af03-c811-48da-9f91-9b831df1ff59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acia.tracking.utils import life_cycle_lineage\n",
    "\n",
    "# create lifecycle lineage (one cell life one node in the graph, in contrast to one cell detection one node in the graph)\n",
    "lc_lineage = life_cycle_lineage(tracking_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353009b7-627f-4044-bd23-b8528c32e9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tracking (temporal) information into pandas data frame\n",
    "lc_df = pd.DataFrame([{\"track_id\": n, \"predecessors\": list(lc_lineage.predecessors(n)), \"successors\": list(lc_lineage.successors(n)), \"cycle\": lc_lineage.nodes[n][\"cycle\"], \"start_frame\": lc_lineage.nodes[n][\"start_frame\"], \"end_frame\": lc_lineage.nodes[n][\"end_frame\"], \"age\": len(lc_lineage.nodes[n][\"cycle\"])  * frame_step} for n in lc_lineage.nodes])\n",
    "\n",
    "lc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3341cf-07b1-4529-8f21-d1c5dc198721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tifffile\n",
    "import numpy as np\n",
    "\n",
    "# cache the image data\n",
    "images = tifffile.imread(image_path)\n",
    "# make them rgb\n",
    "if len(images.shape) == 3 or (len(images.shape) == 4 and images.shape[-1] == 1):\n",
    "    images = np.stack([images] * 3, axis=-1)\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10906863-53a6-44b7-911a-5338fa25c330",
   "metadata": {},
   "source": [
    "## 3. Utility functionalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8220ee7c-efcb-4edb-b349-90b1eeb43a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_lookup = {det_id: track_id for track_id in lc_lineage.nodes() for det_id in lc_lineage.nodes[track_id][\"cycle\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18720203-8fcf-4f07-9a21-ec43613e4cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from acia.base import Overlay\n",
    "\n",
    "def get_frame_overlay(frame: int):\n",
    "    \n",
    "    # operate on the dataframe\n",
    "    return cell_df[cell_df[\"frame\"] == frame] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01980364-7aba-4b22-be88-86c4be24338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_figure(frame:int, selection=None, cell_info=None):\n",
    "    \"\"\"\n",
    "    Creates a plotly figure with images and selected/unselected cell overlay\n",
    "    \"\"\"\n",
    "    \n",
    "    # use only the first channel for the image\n",
    "    image = images[frame][...,0]\n",
    "    \n",
    "    # Render image into figure\n",
    "    compression_level=8\n",
    "    fig = px.imshow(image, binary_string=True, binary_compression_level=compression_level)\n",
    "\n",
    "    if selection is not None:\n",
    "        selection = set(selection)\n",
    "    \n",
    "    fig.update_layout(autosize=True)\n",
    "\n",
    "    # obtain the segmentation of the frame\n",
    "    frame_df = get_frame_overlay(frame)\n",
    "    \n",
    "    # loop over all contours in this frame and create an overlay trace in plotly\n",
    "    for _,contour in frame_df.iterrows():\n",
    "        \n",
    "        coordinates = np.concatenate([contour[\"contour_coordinates\"], contour[\"contour_coordinates\"][0:1]])\n",
    "        x_array = np.array(coordinates[:,0])\n",
    "        y_array = np.array(coordinates[:,1])\n",
    "\n",
    "        color = (255,255,0)\n",
    "        if selection is not None:\n",
    "            if contour.id in selection:\n",
    "                color = (255, 0, 0)\n",
    "\n",
    "        text = f'I am cell {contour.id}'\n",
    "        if cell_info is not None:\n",
    "            text = cell_info[contour.id]\n",
    "\n",
    "        # Adding a trace with a fill, setting opacity to 0\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                x=x_array, \n",
    "                y=y_array, \n",
    "                fill=\"toself\",\n",
    "                fillcolor=f'rgba{tuple([*color, 0.5])}',\n",
    "                mode='lines',\n",
    "                line=dict(\n",
    "                    color=f\"rgb{color}\",\n",
    "                    width=2\n",
    "                ),\n",
    "                name=f'Cell id: {contour.id}',\n",
    "                text=text,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8697be-0628-4898-bbaa-3612bb23e080",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_selection(data, min, max, mode):\n",
    "    low = np.quantile(data, min / 100)\n",
    "    high = np.quantile(data, max / 100)\n",
    "    \n",
    "    data = np.array(data)\n",
    "    \n",
    "    print(low, high)    \n",
    "    \n",
    "    selection = (low <= data) & (data <= high)\n",
    "    if mode == \"Exclusive\":\n",
    "        selection = ~selection # invert the selection\n",
    "        \n",
    "    return selection, low, high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1656ca7c-aebe-42b1-9179-93508b36083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import dash\n",
    "import uuid\n",
    "import cv2\n",
    "import moviepy.editor as mpy\n",
    "\n",
    "\n",
    "def render_video(cell_df, selection_mask=None):\n",
    "    \n",
    "    uid = uuid.uuid4()\n",
    "    thickness = 2\n",
    "    \n",
    "    selected_df = cell_df.iloc[selection_mask]\n",
    "    unselected_df = cell_df.iloc[~selection_mask]\n",
    "\n",
    "    video_images = []\n",
    "    for frame in tqdm(np.unique(cell_df[\"frame\"])):\n",
    "        frame_image = np.copy(images[frame])#source.get_frame(frame).raw\n",
    "        \n",
    "        font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "\n",
    "        # org \n",
    "        org = (50, 50) \n",
    "\n",
    "        # fontScale \n",
    "        fontScale = 0.5\n",
    "\n",
    "        # Blue color in RGB \n",
    "        color = (255, 255, 255) \n",
    "\n",
    "        # Line thickness of 2 px \n",
    "        thickness = 2\n",
    "        \n",
    "        cv2.putText(frame_image, f\"Frame {frame:02d}\", org, font,  \n",
    "                   fontScale, color, thickness, cv2.LINE_AA)\n",
    "        \n",
    "        sel_frame_df = selected_df[selected_df[\"frame\"] == frame]\n",
    "        unsel_frame_df = unselected_df[unselected_df[\"frame\"] == frame]\n",
    "\n",
    "        cv2.polylines(frame_image, [np.array(cell_data[\"contour_coordinates\"]).astype(np.int32) for _,cell_data in sel_frame_df.iterrows()], True, (255, 0, 0), thickness)\n",
    "        cv2.polylines(frame_image, [np.array(cell_data[\"contour_coordinates\"]).astype(np.int32) for _,cell_data in unsel_frame_df.iterrows()], True, (255, 255, 0), thickness)\n",
    "\n",
    "        video_images.append(frame_image)\n",
    "        \n",
    "    clip =  mpy.ImageSequenceClip(video_images, fps=10)\n",
    "    crf=23\n",
    "    filename=f\"assets/test-{uid}.mp4\"\n",
    "    clip.write_videofile(\n",
    "            filename, \n",
    "            codec='vp9',ffmpeg_params=[\"-quality\", \"realtime\", \"-speed\", \"4\"] # preset=\"ultrafast\", ffmpeg_params=[\"-crf\", str(crf)],\n",
    "    )\n",
    "\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c3fa06-eb5d-4162-b402-359f2adb1550",
   "metadata": {},
   "source": [
    "## 4. Compute single-cell stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f413cd45-ed09-4794-b10e-676d1524d1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "track_lookup = {det_id: n for n in lc_lineage.nodes for det_id in lc_lineage.nodes[n][\"cycle\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7c8cf-2530-4e7a-9319-f831f749b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add track id to every cell detection\n",
    "cell_df[\"track_id\"] = cell_df[\"id\"].map(lambda cid: track_lookup[cid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e2f6ad-425b-43b9-b2fa-5d506932609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the amount of smaller cells\n",
    "cell_df[\"area_smaller\"] = cell_df.apply(lambda x: np.sum(cell_df['area'] <= x['area']) / len(cell_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9911883-304f-4976-b6f5-7f9697f2e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add trajectory age to every cell detection\n",
    "cell_df[\"track_age\"] = cell_df[\"track_id\"].map(lambda track_id: lc_df[lc_df[\"track_id\"] == track_id].iloc[0][\"age\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f469b9-cc2c-41ea-93d5-c034fb29ea2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b3176-6e04-49e1-bcc2-a568e167d8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df[\"age_younger\"] = cell_df.apply(lambda x: np.sum(lc_df[\"age\"] <= x[\"track_age\"]) / len(lc_df), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3c810-a96c-4434-8b1a-8c55fe2fa460",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df[\"cell_info\"] = cell_df.apply(lambda x: f\"I am cell {x['id']}<br />\", axis=1) #Cell detection info:<br />area: { x['area_smaller'] * 100:.1f }% <= {x['area']} <= {(1 - x['area_smaller']) * 100:.1f}%<br /><br />Cell track info:<br />age: {x['age_younger'] * 100:.1f}% <= {x['track_age']} <= {(1 - x['age_younger']) * 100:.1f}%\", axis=1)\n",
    "\n",
    "cell_info = {x['id']: x['cell_info'] for _, x in cell_df.iterrows()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2928c94-568e-4b20-ad2e-58744c1776da",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, x in tqdm(cell_df[[\"id\", \"track_age\"]].iterrows()):\n",
    "    track_id = lc_lookup[x[\"id\"]]\n",
    "    assert len(lc_lineage.nodes[track_id][\"cycle\"]) * frame_step == x[\"track_age\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803b8c55-b16c-4ad2-bdbd-c2474b2321bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc305d6-0f5a-49f1-ab32-0dbf1f1e3ef6",
   "metadata": {},
   "source": [
    "## 5. Create the interactive visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502b220-f1de-4701-ba1f-5f9880b09554",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video, Markdown, display\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "import plotly.io as pio\n",
    "import plotly.express as px\n",
    "\n",
    "from dash import Dash, dcc, html, Input, Output, callback, no_update, State, ctx\n",
    "import os\n",
    "import json\n",
    "\n",
    "from PIL import Image\n",
    "from pandas import DataFrame\n",
    "import pandas as pd\n",
    "import plotly.figure_factory as ff\n",
    "from functools import reduce\n",
    "\n",
    "from dash.long_callback import DiskcacheLongCallbackManager\n",
    "\n",
    "## Create Diskcache (for long running video creation)\n",
    "import diskcache\n",
    "cache = diskcache.Cache(\"./cache\")\n",
    "long_callback_manager = DiskcacheLongCallbackManager(cache)\n",
    "\n",
    "min_frame = 0\n",
    "max_frame = len(images) - 1\n",
    "\n",
    "# extract single-cell properties for filtering\n",
    "areas = np.array(cell_df[\"area\"])\n",
    "ages = np.array(cell_df[\"track_age\"])\n",
    "lengths = np.array(cell_df[\"length\"])\n",
    "\n",
    "\n",
    "app = Dash(__name__, external_stylesheets=[dbc.themes.BOOTSTRAP])\n",
    "\n",
    "#############################\n",
    "### Create the App layout ###\n",
    "#############################\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Store(id='memory'),\n",
    "    dbc.Row([\n",
    "        dbc.Col([\n",
    "            # graph for microscope image\n",
    "            dcc.Loading(dcc.Graph(id=\"image\")),\n",
    "            # frame slider\n",
    "            dbc.Col(dcc.Slider(min_frame, max_frame, step=1, value=5, id='frame-slider', tooltip={\"placement\": \"bottom\", \"always_visible\": True}, marks={0: '0', max_frame: f'{max_frame}'},), width=12),\n",
    "            # video download button\n",
    "            dbc.Col(html.Div(dbc.Button(\"Download Video\", id=\"btn_video\", color=\"primary\"), className=\"d-grid gap-2\"), width=12),\n",
    "            dcc.Download(id=\"download-video\")\n",
    "        ], width=4),\n",
    "        dbc.Col([\n",
    "            # normalize button\n",
    "            dbc.Row([\n",
    "                dbc.Checklist(\n",
    "                    options=[\n",
    "                        {\"label\": \"Normalize\", \"value\": \"normalize\"},\n",
    "                    ],\n",
    "                    value=[],\n",
    "                    id=\"normalized-input\",\n",
    "                    switch=True,\n",
    "                ),\n",
    "            ]),\n",
    "            # cell size graph\n",
    "            dbc.Row(dcc.Loading(dcc.Graph(id=\"lineage\", mathjax=True))),\n",
    "            # cell count graph\n",
    "            dbc.Row(dcc.Loading(dcc.Graph(id=\"counts\", mathjax=True))),\n",
    "        ], width=8),\n",
    "\n",
    "    ]),\n",
    "    dbc.Row([\n",
    "        # distribution for cell area\n",
    "        dbc.Col(dcc.Loading([\n",
    "            dcc.Graph(id=\"area-dist\", mathjax=True),\n",
    "            dcc.RadioItems(['Inclusive', 'Exclusive'], 'Inclusive', id=\"area-radio\"),\n",
    "            dcc.RangeSlider(0, 100, value=[0, 100], id='area-slider', allowCross=False, tooltip={\"placement\": \"bottom\", \"always_visible\": True}, marks={0: '0', 100: f'100'},)\n",
    "        ]), width=4),\n",
    "        # distribution for cell length\n",
    "        dbc.Col(dcc.Loading([\n",
    "            dcc.Graph(id=\"end-area-ratio\", mathjax=True),#figure=age_fig, id=\"age-dist\"),\n",
    "            dcc.RadioItems(['Inclusive', 'Exclusive'], 'Inclusive', id=\"length-radio\"),\n",
    "            dcc.RangeSlider(0, 100, value=[0, 100], id='length-slider', allowCross=False, tooltip={\"placement\": \"bottom\", \"always_visible\": True}, marks={0: '0', 100: f'100'},),\n",
    "        ]), width=4),\n",
    "        # distribution for cell age\n",
    "        dbc.Col(dcc.Loading([\n",
    "            dcc.Graph(id=\"age-dist\", mathjax=True),\n",
    "            dcc.RadioItems(['Inclusive', 'Exclusive'], 'Inclusive', id=\"age-radio\"),\n",
    "            dcc.RangeSlider(0, 100, value=[0, 100], id='age-slider', allowCross=False, tooltip={\"placement\": \"bottom\", \"always_visible\": True}, marks={0: '0', 100: f'100'},),\n",
    "        ]), width=4),\n",
    "    ])\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"memory\", \"data\"),\n",
    "    Output(\"lineage\", \"figure\"),\n",
    "    Output(\"counts\", \"figure\"),\n",
    "    Output(\"image\", \"figure\"),\n",
    "    Output(\"area-dist\", \"figure\"),\n",
    "    Output(\"age-dist\", \"figure\"),\n",
    "    Output(\"end-area-ratio\", \"figure\"),\n",
    "    Input(\"normalized-input\", \"value\"),\n",
    "    Input(\"image\", \"clickData\"),\n",
    "    Input(\"frame-slider\", \"value\"),\n",
    "    Input(\"area-slider\", \"value\"),\n",
    "    Input(\"area-radio\", \"value\"),\n",
    "    Input(\"length-slider\", \"value\"),\n",
    "    Input(\"length-radio\", \"value\"),\n",
    "    Input(\"age-slider\", \"value\"),\n",
    "    Input(\"age-radio\", \"value\"),\n",
    "    State(\"memory\", \"data\")\n",
    ")\n",
    "def update_figures(normalized_input, target_click, frame_slider, area_slider, area_radio, length_slider, length_radio, age_slider, age_radio, data):\n",
    "    trigger_id = ctx.triggered_id\n",
    "    print(trigger_id)\n",
    "    print(frame_slider)\n",
    "    print(area_slider)\n",
    "    print(age_slider)\n",
    "    #print(start_click)\n",
    "    \n",
    "    if data is None:\n",
    "        data = {}\n",
    "        data[\"start_selection\"] = []\n",
    "    \n",
    "    # frame selected by the slider\n",
    "    target_frame = frame_slider\n",
    "\n",
    "    # compute area and length selections\n",
    "    area_selection, area_low, area_high = compute_selection(areas, area_slider[0], area_slider[1], area_radio)\n",
    "    length_mask, length_low, length_high = compute_selection(lengths, length_slider[0], length_slider[1], length_radio)\n",
    "    \n",
    "\n",
    "    # compute age selection (a bit more difficult, because it affects full trajectories of cells)\n",
    "    low = np.quantile(lc_df[\"age\"], age_slider[0] / 100)\n",
    "    high = np.quantile(lc_df[\"age\"], age_slider[1] / 100)\n",
    "    \n",
    "    \n",
    "    inclusive_set_selection = (low <= ages) & (ages <= high)\n",
    "    print(inclusive_set_selection)\n",
    "    if age_radio == \"Inclusive\":\n",
    "        age_subset = ages[inclusive_set_selection]\n",
    "    else:\n",
    "        age_subset = ages[~inclusive_set_selection]\n",
    "\n",
    "    \n",
    "    sc_age_mask = inclusive_set_selection #cell_df[\"id\"].isin(sc_age_selection)\n",
    "\n",
    "    \n",
    "    # fuse all selections into a mask\n",
    "    total_selection_mask = area_selection & sc_age_mask & length_mask\n",
    "    total_selection = set(cell_df[\"id\"][total_selection_mask])\n",
    "    \n",
    "\n",
    "    # create the image figure using the selection mask\n",
    "    end_fig = get_image_figure(target_frame, total_selection, cell_info)\n",
    "    end_fig.update_layout(\n",
    "        height=700,\n",
    "        showlegend=False\n",
    "    )\n",
    "    \n",
    "    ##########################################\n",
    "    # Create area and count over time figure #\n",
    "    ##########################################\n",
    "    \n",
    "    area_df = cell_df[[\"id\", \"frame\", \"area\", \"time\"]]\n",
    "    length_df = cell_df[[\"id\", \"frame\", \"length\", \"time\"]]\n",
    "    age_df = cell_df[[\"id\", \"frame\", \"track_age\", \"time\"]]\n",
    "    \n",
    "    # selected cell areas\n",
    "    df_unselected = area_df[~total_selection_mask].groupby(\"time\").agg(\"sum\").reset_index()\n",
    "    df_selected = area_df[total_selection_mask].groupby(\"time\").agg(\"sum\").reset_index()\n",
    "    df_selected[\"type\"] = \"selected\"\n",
    "    df_unselected[\"type\"] = \"unselected\"\n",
    "    \n",
    "    # selected cell counts\n",
    "    df_unselected_sizes = area_df[~total_selection_mask].groupby(\"time\").size().reset_index(name=\"cell_count\")\n",
    "    df_selected_sizes = area_df[total_selection_mask].groupby(\"time\").size().reset_index(name=\"cell_count\")\n",
    "    df_selected_sizes[\"type\"] = \"selected\"\n",
    "    df_unselected_sizes[\"type\"] = \"unselected\"\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    df_area = pd.concat([df_unselected, df_selected])\n",
    "    df_counts = pd.concat([df_unselected_sizes, df_selected_sizes])\n",
    "    \n",
    "    # compute normalized values\n",
    "    grouped = df_area.groupby(\"time\")\n",
    "    df_area['area_norm'] = grouped['area'].transform(lambda x: x/x.sum())\n",
    "\n",
    "    grouped = df_counts.groupby(\"time\")\n",
    "    df_counts['cell_count_norm'] = grouped['cell_count'].transform(lambda x: x/x.sum())\n",
    "    \n",
    "    # based on normalizer button choose which data column to use\n",
    "    y_post = ''\n",
    "    if \"normalize\" in normalized_input:\n",
    "        y_post = \"_norm\"\n",
    "        \n",
    "    color_discrete_map= {\"selected\": \"rgb(255, 0, 0)\", \"unselected\": \"rgb(255, 255, 0)\"}\n",
    "    \n",
    "    # create the figures\n",
    "    figures = [\n",
    "        px.area(df_area, x=\"time\", y=\"area\" + y_post, color=\"type\", title=\"Cell Area Over Time\", color_discrete_map=color_discrete_map),\n",
    "        px.area(df_counts, x=\"time\", y=\"cell_count\" + y_post, color=\"type\", title=\"Cell Count Over Time\", color_discrete_map=color_discrete_map),\n",
    "    ]\n",
    "    \n",
    "    for figure in figures:\n",
    "        figure.update_layout(\n",
    "            xaxis=dict(\n",
    "                spikemode  = 'across+toaxis', spikedash = 'solid'\n",
    "            ),\n",
    "            xaxis_title=\"Time [hour]\",\n",
    "            margin=dict(\n",
    "                r=0,\n",
    "                b=0,\n",
    "            ),\n",
    "            height=400\n",
    "        )\n",
    "        figure.update_traces(hovertemplate=None)\n",
    "        figure.update_layout(hovermode=\"x\")\n",
    "        \n",
    "    figures[0].update_layout(\n",
    "        yaxis_title=r\"$\\text{Total cell area [} \\mu m \\text{]}$\"\n",
    "    )\n",
    "    figures[1].update_layout(\n",
    "        yaxis_title=r\"$\\text{Total cell count}$\"\n",
    "    )\n",
    "    \n",
    "    ##########################\n",
    "    # Create histogram plots #\n",
    "    ##########################\n",
    "    \n",
    "    area_fig = px.histogram(cell_df, x=\"area\", nbins=100)\n",
    "    \n",
    "    area_fig.update_layout(\n",
    "        title=\"Area Distribution\",\n",
    "        autosize=True,\n",
    "        xaxis_title=r\"$\\text{Cell size [} \\mu m^2 \\text{]}$\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "    )\n",
    "    \n",
    "    area_fig.add_vline(x=area_low, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    area_fig.add_vline(x=area_high, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "            \n",
    "    age_fig = px.histogram(lc_df, x=\"age\", nbins=100)\n",
    "    \n",
    "    age_fig.add_vline(x=low, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    age_fig.add_vline(x=high, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "    age_fig.update_layout(\n",
    "        title=\"Age Distribution\",\n",
    "        xaxis_title=\"Cell age [hour]\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "    )\n",
    "    \n",
    "    length_fig = px.histogram(cell_df, x=\"length\", nbins=100)\n",
    "    \n",
    "    length_fig.add_vline(x=length_low, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "    length_fig.add_vline(x=length_high, line_width=3, line_dash=\"dash\", line_color=\"green\")\n",
    "\n",
    "    \n",
    "    length_fig.update_layout(\n",
    "        title=\"Length Distribution\",\n",
    "        autosize=True,\n",
    "        xaxis_title=r\"$\\text{Cell length [} \\mu m \\text{]}$\",\n",
    "        yaxis_title=\"Frequency\",\n",
    "    )\n",
    "    \n",
    "    \n",
    "    return {\"mask\": total_selection_mask}, figures[0], figures[1], end_fig, area_fig, age_fig, length_fig\n",
    "\n",
    "@app.long_callback(\n",
    "    Output(\"download-video\", \"data\"),\n",
    "    Input(\"btn_video\", \"n_clicks\"),\n",
    "    Input(\"memory\", \"data\"),\n",
    "    prevent_initial_call=True,\n",
    "    manager=long_callback_manager,\n",
    ")\n",
    "def gen_video(clicks, data):\n",
    "    trigger_id = ctx.triggered_id\n",
    "    \n",
    "    if trigger_id != \"btn_video\":\n",
    "        return None\n",
    "    \n",
    "    # 1. gen video file\n",
    "    \n",
    "    print(\"Start generating video file...\")\n",
    "    \n",
    "    #print(gen_video)\n",
    "    output_file = render_video(cell_df, np.array(data[\"mask\"], bool))\n",
    "    \n",
    "    return dcc.send_file(\n",
    "        output_file\n",
    "    )\n",
    "\n",
    "\n",
    "display(Markdown(\"# View 03: Explore single-cell distributions\"))\n",
    "app.run_server(port=8052, jupyter_mode=\"inline\", jupyter_height=1600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6c2bf1-2f92-42a1-bc10-d5fef3a74439",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
